# Babylon Environment Configuration
# Copy to .env and fill in your values

# =============================================================================
# LLM CHAT (DeepSeek cloud - primary)
# =============================================================================
DEEPSEEK_API_KEY=your-deepseek-key
LLM_API_BASE=https://api.deepseek.com
LLM_CHAT_MODEL=deepseek-chat

# =============================================================================
# EMBEDDINGS (Ollama local - default, no API key needed)
# =============================================================================
LLM_EMBEDDING_PROVIDER=ollama
LLM_EMBEDDING_API_BASE=http://localhost:11434
LLM_EMBEDDING_MODEL=embeddinggemma:latest

# To use OpenAI embeddings instead (cloud):
# LLM_EMBEDDING_PROVIDER=openai
# LLM_EMBEDDING_API_BASE=https://api.openai.com
# OPENAI_API_KEY=your-openai-key
# LLM_EMBEDDING_MODEL=text-embedding-ada-002

# =============================================================================
# CHROMADB (Local vector database)
# =============================================================================
CHROMADB_PERSIST_DIR=./chromadb

# =============================================================================
# DATABASE (SQLite - local)
# =============================================================================
DATABASE_URL=sqlite:///babylon.db

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
DEBUG=false
TESTING=false
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_DIR=./logs

# =============================================================================
# METRICS & PERFORMANCE
# =============================================================================
METRICS_ENABLED=true
METRICS_INTERVAL=60

# =============================================================================
# RATE LIMITING (for cloud APIs)
# =============================================================================
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=1.0
LLM_RATE_LIMIT_RPM=60
LLM_BATCH_SIZE=8
LLM_REQUEST_TIMEOUT=30.0

# =============================================================================
# LEGACY (OpenAI-specific, for backward compatibility)
# =============================================================================
# OPENAI_API_KEY=your-openai-key
# OPENAI_ORGANIZATION_ID=optional-org-id
