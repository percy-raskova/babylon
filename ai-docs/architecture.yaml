# Babylon System Architecture
# How the pieces fit together

meta:
  version: "3.4.0"
  updated: "2025-12-14"
  status: "Phase 3.4 in progress (1,926 tests, Narrative Bridge complete)"
  related_docs:
    - "ai-docs/database-spec.yaml - SQLite schema and DDL"
    - "ai-docs/rag-architecture.yaml - ChromaDB collections"
    - "ai-docs/formulas-spec.yaml - Mathematical formulas"

# =============================================================================
# THE EMBEDDED TRINITY
# =============================================================================

core_architecture:
  name: "The Embedded Trinity"
  principle: "Three-layer local system, no external servers"

  layers:
    ledger:
      purpose: "Rigid, material state (persistent storage)"
      technology: "SQLite + Pydantic"
      location: "src/babylon/data/"
      schema_spec: "ai-docs/database-spec.yaml"
      contains:
        - "babylon.db: SQLite database (social_classes, territories, relationships)"
        - "persistence.py: PersistenceService (hydration/dehydration)"
        - "Pydantic models for validation"
      tables:
        social_classes: "SocialClass entities with IdeologicalProfile columns"
        territories: "Territory entities (Layer 0 spatial substrate)"
        relationships: "Directed edges (exploitation, solidarity, etc.)"
      data_flow: "Hydration Pattern - load at startup, persist on save, NO DB I/O during tick"
      key_insight: "Database is cold storage; simulation runs in RAM"

    topology:
      purpose: "Fluid, relational state (hot computation environment)"
      technology: "NetworkX (in-memory graph)"
      locations:
        primary: "src/babylon/models/world_state.py (to_graph/from_graph)"
        formulas: "src/babylon/systems/formulas.py"
        engine: "src/babylon/engine/simulation_engine.py"
      contains:
        - "WorldState.to_graph() - DiGraph of entities and relationships"
        - "Relationship edges (EXPLOITATION, SOLIDARITY, REPRESSION)"
        - "Node attributes (wealth, ideology, organization, p_*)"
        - "Edge attributes (value_flow, tension, solidarity_strength)"
      data_flow: "Hydrated from Ledger → mutated during tick → dehydrated back"
      key_insight: "Graph + Math = History (ADR011)"
      runtime_constraint: "No database queries during tick - pure RAM operations"

    archive:
      purpose: "Semantic history and theory"
      technology: "ChromaDB + embeddings"
      location: "src/babylon/rag/"
      contains:
        - "Historical events"
        - "Theoretical texts (MLM-TW corpus) - NOT YET POPULATED"
        - "Past game states for narrative"
      data_flow: "AI queries for context, generates narrative from state changes"
      key_insight: "AI observes and narrates, never controls mechanics"
      current_status: "Infrastructure complete, ChromaDB empty (no corpus ingested)"

    superstructure:
      purpose: "AI narrative layer (Phase 3)"
      technology: "Observer Pattern + LLM Provider"
      location: "src/babylon/ai/"
      contains:
        - "NarrativeDirector - SimulationObserver implementation"
        - "DialecticalPromptBuilder - context hierarchy assembly"
        - "LLM Provider (planned) - Claude/Ollama/DeepSeek abstraction"
      data_flow: "Observes state → Queries RAG → Builds prompt → Calls LLM → Outputs narrative"
      key_insight: "Read-only access to simulation state (ADR003)"
      current_status: "Observer + RAG complete, LLM integration pending (Sprint 3.3)"

# =============================================================================
# DIRECTORY STRUCTURE
# =============================================================================

directory_map:
  src/babylon/:
    config/: "BaseConfig, environment variables, logging setup"
    core/:
      purpose: "Legacy topology layer (partially deprecated)"
      status: "economy.py and politics.py DELETED per ADR011"
      key_files:
        - "contradiction.py: Legacy ContradictionAnalysis"
        - "entity.py: Base Entity class"
      note: "See engine/ and systems/ for Phase 2+ implementation"

    engine/:
      purpose: "Simulation engine - the Phase 2 game loop"
      key_files:
        - "simulation_engine.py: SimulationEngine class + step() function"
        - "services.py: ServiceContainer (dependency injection)"
        - "event_bus.py: EventBus (publish/subscribe)"
        - "formula_registry.py: FormulaRegistry (12 formulas)"
        - "database.py: DatabaseConnection (SQLAlchemy)"
        - "simulation.py: Simulation facade class"
        - "factories.py: create_proletariat(), create_bourgeoisie()"
        - "scenarios.py: Factory functions for test scenarios"
        - "history_formatter.py: format_class_struggle_history()"
      subdirs:
        systems/:
          purpose: "Modular System implementations (8 Systems)"
          files:
            - "protocol.py: System protocol with step(graph, services, context)"
            - "economic.py: ImperialRentSystem - wealth extraction via imperial rent"
            - "solidarity.py: SolidaritySystem - consciousness transmission via SOLIDARITY edges"
            - "ideology.py: ConsciousnessSystem - ideology drift & bifurcation"
            - "survival.py: SurvivalSystem - P(S|A), P(S|R) calculations"
            - "struggle.py: StruggleSystem - Agency Layer (George Floyd Dynamic)"
            - "contradiction.py: ContradictionSystem - tension/rupture dynamics"
            - "territory.py: TerritorySystem - heat, eviction, carceral geography"
            - "event_template.py: EventTemplateSystem - structured event templates"
        history/:
          purpose: "State persistence and undo/redo"
          files:
            - "models.py: HistoryStack, Checkpoint, CheckpointConfig"
            - "stack.py: push_state, undo, redo, prune_history"
            - "io.py: save_state, load_state, atomic writes"
            - "auto_checkpoint.py: AutoCheckpointer"
      status: "IMPLEMENTED (150+ tests)"

    models/:
      purpose: "Pydantic models for the simulation"
      key_files:
        - "world_state.py: Immutable state snapshot with NetworkX integration"
        - "config.py: SimulationConfig (frozen, 11 parameters)"
        - "types.py: Constrained types (Probability, Currency, Ideology, etc.)"
        - "enums.py: StrEnum definitions (SocialRole, EdgeType, etc.)"
      subdirs:
        entities/:
          purpose: "Game entity models"
          files:
            - "social_class.py: SocialClass (Phase 1 node)"
            - "relationship.py: Relationship (Phase 1 edge)"
            - "effect.py, contradiction.py, trigger.py: Supporting models"
        components/:
          purpose: "Component system (Material Ontology)"
          files:
            - "base.py: Component protocol"
            - "material.py: MaterialComponent (wealth, resources, means_of_production)"
            - "vitality.py: VitalityComponent (population, subsistence_needs)"
            - "spatial.py: SpatialComponent (location_id, mobility)"
            - "ideological.py: IdeologicalComponent (alignment, adherence)"
            - "organization.py: OrganizationComponent (cohesion, cadre_level)"
      status: "IMPLEMENTED (200+ tests)"
    data/:
      purpose: "Ledger layer - persistent state"
      key_files:
        - "entity_registry.py: Entity lookup"
      subdirs:
        game/:
          purpose: "Game data JSON files"
          files: "17 entity collection JSON files (characters, factions, classes, etc.)"
        xml/:
          purpose: "Legacy XML (reference only)"
    schemas/:
      purpose: "JSON Schema validation"
      structure:
        - "core/common.schema.json: Shared $defs"
        - "core/base.schema.json: Metadata envelope"
        - "entities/*.schema.json: 17 entity schemas"
        - "collections/*.schema.json: 17 collection schemas"
    ai/:
      purpose: "Superstructure layer - AI narrative generation (Phase 3)"
      key_files:
        - "director.py: NarrativeDirector (SimulationObserver)"
        - "prompt_builder.py: DialecticalPromptBuilder (context hierarchy)"
        - "llm_provider.py: LLM abstraction (PLANNED - Sprint 3.3)"
      status: "IMPLEMENTED (59 tests)"
      data_flow: |
        1. NarrativeDirector.on_tick(prev, new) called by Simulation
        2. Detect new events in WorldState.event_log
        3. Query RagPipeline for historical/theoretical context
        4. Build context block via DialecticalPromptBuilder
        5. Call LLM provider (NOT YET IMPLEMENTED)
        6. Output narrative text

    rag/:
      purpose: "Archive layer - semantic memory"
      key_files:
        - "rag_pipeline.py: RagPipeline (query interface)"
        - "retrieval.py: QueryResponse, QueryResult models"
        - "embeddings.py: Embedding generation"
        - "chunker.py: Document chunking"
        - "chroma_manager.py: ChromaDB client management"
      status: "Infrastructure complete, NO DATA POPULATED"
      note: "ChromaDB collections are empty - no corpus ingested yet"

    systems/:
      purpose: "Game systems implementation"
      key_files:
        - "formulas.py: Mathematical core"
        - "contradiction_analysis.py: Dialectical engine"
    metrics/: "Performance and gameplay metrics"
    utils/: "Shared utilities, exceptions"

  tools/:
    purpose: "CLI utilities"
    key_files:
      - "migrate_xml_to_json.py: Legacy migration"
      - "validate_schemas.py: Schema validation"

  tests/:
    structure:
      - "unit/: Fast, deterministic tests"
      - "fixtures/: Test data"
      - "mocks/: Test doubles"
    markers:
      - "math: Pure formula tests"
      - "ledger: State tests"
      - "topology: Graph tests"
      - "integration: I/O tests"
      - "ai: Slow AI evals"

  brainstorm/: "Ideas not yet ready for implementation"
  ai-docs/: "Machine-readable docs for AI assistants"

# =============================================================================
# DATA FLOW: THE HYDRATION CYCLE
# =============================================================================

data_flows:
  overview: |
    The Embedded Trinity uses a "Hydration Pattern" for data flow.
    The Engine does NOT query SQL during simulation - it loads SQL into
    NetworkX (RAM), mutates it, and dumps it back. This ensures:
    1. Deterministic simulation (no I/O latency or race conditions)
    2. Fast tick execution (pure RAM operations)
    3. Clean separation between storage and computation

  # ---------------------------------------------------------------------------
  # PHASE 1: HYDRATION (Wake)
  # ---------------------------------------------------------------------------
  hydration:
    name: "Wake"
    when: "Game startup, load save, new game"
    input: "SQLite tables (social_classes, territories, relationships)"
    output: "WorldState (Pydantic) → NetworkX DiGraph"

    process:
      service: "PersistenceService.load_state()"
      steps:
        - "1. Query SQLite tables (SELECT * FROM social_classes, territories, relationships)"
        - "2. Validate rows against Pydantic models (SocialClass, Territory, Relationship)"
        - "3. Construct WorldState from validated entities"
        - "4. Convert WorldState.to_graph() → NetworkX DiGraph"
        - "5. Initialize ChromaDB connection for Archive layer"

    sql_operations:
      social_classes: "SELECT * FROM social_classes"
      territories: "SELECT * FROM territories"
      relationships: "SELECT * FROM relationships"

    pydantic_validation: |
      Each row is validated through the corresponding Pydantic model:
      - SocialClass: Validates IdeologicalProfile (class_consciousness, national_identity, agitation)
      - Territory: Validates profile enum, heat bounds, foreign key references
      - Relationship: Validates edge_type enum, solidarity_strength bounds

    output_structure:
      worldstate: "Immutable Pydantic model with all entities"
      graph: "NetworkX DiGraph with nodes and edges"

  # ---------------------------------------------------------------------------
  # PHASE 2: SIMULATION (Work)
  # ---------------------------------------------------------------------------
  simulation:
    name: "Work"
    when: "Each tick of the game loop"
    environment: "Pure RAM (NetworkX DiGraph)"
    constraint: "NO DATABASE I/O DURING TICK"

    process:
      implementation: "step(WorldState, SimulationConfig) → WorldState"
      location: "src/babylon/engine/simulation_engine.py"
      steps:
        - "1. WorldState already in RAM (from hydration or previous tick)"
        - "2. Convert to NetworkX DiGraph if not already"
        - "3. Create ServiceContainer with config (no DB reference)"
        - "4. Run Systems in historical materialist order"
        - "5. Convert graph back to new WorldState"
        - "6. Return new immutable WorldState (old state unchanged)"

    systems_execution:
      order: "Historical materialist causality"
      systems:
        - "1. ImperialRentSystem: Extract surplus value along EXPLOITATION edges"
        - "2. SolidaritySystem: Transmit consciousness along SOLIDARITY edges"
        - "3. ConsciousnessSystem: Apply ideological routing (agitation → consciousness/identity)"
        - "4. SurvivalSystem: Calculate P(S|A) and P(S|R)"
        - "5. ContradictionSystem: Accumulate tension, check rupture thresholds"
        - "6. TerritorySystem: Update heat, check eviction thresholds"

    physics_calculations:
      pure_math: |
        All calculations are pure functions on graph state:
        - Wealth transfers along edges
        - Consciousness drift via formulas
        - Heat accumulation/decay
        - Probability updates
      no_side_effects: |
        Systems mutate the graph in place but never:
        - Query the database
        - Write to disk
        - Make network calls
        - Access external state

    services:
      container: "ServiceContainer aggregates dependencies (no DatabaseConnection during tick)"
      config: "SimulationConfig (frozen, 11 parameters)"
      formulas: "FormulaRegistry (12 hot-swappable formulas)"
      event_bus: "EventBus for event publishing (in-memory)"

  # ---------------------------------------------------------------------------
  # PHASE 3: DEHYDRATION (Sleep)
  # ---------------------------------------------------------------------------
  dehydration:
    name: "Sleep"
    when: "Save game, auto-checkpoint, session end"
    input: "WorldState (post-tick Pydantic model)"
    output: "SQLite tables updated via INSERT OR REPLACE"

    process:
      service: "PersistenceService.save_state()"
      steps:
        - "1. Extract entities from WorldState (classes, territories, relationships)"
        - "2. Convert Pydantic models to row dicts"
        - "3. Execute INSERT OR REPLACE for each table"
        - "4. Commit transaction (atomic write)"
        - "5. Optionally update ZEITGEIST collection in ChromaDB"

    sql_operations:
      social_classes: |
        INSERT OR REPLACE INTO social_classes
        (id, name, role, wealth, class_consciousness, national_identity, agitation, ...)
        VALUES (?, ?, ?, ?, ?, ?, ?, ...)
      territories: |
        INSERT OR REPLACE INTO territories
        (id, name, sector_type, host_id, occupant_id, profile, heat, rent_level, ...)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ...)
      relationships: |
        INSERT OR REPLACE INTO relationships
        (source_id, target_id, edge_type, value_flow, tension, solidarity_strength, ...)
        VALUES (?, ?, ?, ?, ?, ?, ...)

    transaction_safety: |
      All writes are wrapped in a transaction:
      - BEGIN TRANSACTION
      - [all INSERT OR REPLACE statements]
      - COMMIT
      On failure: ROLLBACK (database unchanged)

    zeitgeist_update: |
      Optionally append tick summary to THE_ZEITGEIST collection:
      - Tick number
      - Key events
      - State vector embedding
      - Shock value (distance from previous tick)

  # ---------------------------------------------------------------------------
  # HYDRATION CYCLE DIAGRAM
  # ---------------------------------------------------------------------------
  cycle_diagram: |
    ┌─────────────────────────────────────────────────────────────────────────┐
    │                         THE HYDRATION CYCLE                             │
    └─────────────────────────────────────────────────────────────────────────┘

    ┌──────────────┐     HYDRATE      ┌──────────────┐     SIMULATE     ┌──────────────┐
    │   SQLite     │ ───────────────► │  WorldState  │ ───────────────► │  NetworkX    │
    │   (Cold)     │  load_state()    │  (Pydantic)  │   to_graph()     │   (Hot)      │
    │              │                  │              │                  │              │
    │ social_      │                  │ classes: []  │                  │  Nodes:      │
    │   classes    │                  │ territories: │                  │   C001, C002 │
    │ territories  │                  │   []         │                  │   T001, T002 │
    │ relationships│                  │ relations: []│                  │  Edges:      │
    └──────────────┘                  └──────────────┘                  │   C001→C002  │
           ▲                                                            │   (exploit)  │
           │                                                            └──────────────┘
           │                                                                   │
           │                                                                   │
           │                           PHYSICS                                 │
           │                         (Pure RAM)                                │
           │                      No DB I/O here!                              │
           │                                                                   │
           │                                                                   ▼
    ┌──────────────┐     DEHYDRATE    ┌──────────────┐     EXTRACT      ┌──────────────┐
    │   SQLite     │ ◄─────────────── │  WorldState  │ ◄─────────────── │  NetworkX    │
    │   (Cold)     │  save_state()    │  (Pydantic)  │   from_graph()   │   (Hot)      │
    │              │                  │              │                  │              │
    │ INSERT OR    │                  │ New state    │                  │  Mutated     │
    │ REPLACE      │                  │ (immutable)  │                  │  graph       │
    └──────────────┘                  └──────────────┘                  └──────────────┘

  # ---------------------------------------------------------------------------
  # AI NARRATIVE FLOW (Observer Pattern)
  # ---------------------------------------------------------------------------
  ai_narrative:
    principle: "AI is observer, not controller (ADR003)"
    status: "Partially implemented - LLM call missing"
    implementation:
      observer: "NarrativeDirector implements SimulationObserver"
      context: "DialecticalPromptBuilder assembles context hierarchy"
      retrieval: "RagPipeline queries ChromaDB (currently empty)"
      llm: "NOT YET IMPLEMENTED - Sprint 3.3"
    steps:
      - "Simulation.step() calls observer.on_tick(prev_state, new_state)"
      - "NarrativeDirector detects new events in event_log"
      - "Query RagPipeline for relevant history/theory"
      - "Build context block: Material Conditions → RAG Context → Events"
      - "Call LLM provider (MISSING)"
      - "Output narrative text"
      - "Never modify game mechanics"
    gaps_identified:
      - "ChromaDB has no corpus data (RAG returns empty)"
      - "Only ContradictionSystem emits events (rupture only)"
      - "No LLM client implementation"
      - "No CLI runner for vertical slice demo"

# =============================================================================
# KEY INTERFACES
# =============================================================================

interfaces:

  entity_to_ledger:
    pattern: "Pydantic models validated against JSON Schema"
    example: "Faction model → factions.json → factions.schema.json"

  ledger_to_topology:
    pattern: "JSON data → NetworkX nodes/edges"
    example: "faction.dialectical_relationships → graph edges"

  topology_to_archive:
    pattern: "State changes → ChromaDB queries → narrative"
    example: "Contradiction intensified → find similar historical events → generate description"

# =============================================================================
# CAUSAL DAG: FUNDAMENTALS → SYSTEMS → METRICS
# =============================================================================
# Understanding the flow from input parameters to observable outputs

causal_dag:
  description: |
    The simulation follows a strict causal hierarchy:
    1. FUNDAMENTALS (GameDefines) are the independent variables we control
    2. SYSTEMS transform state according to formulas
    3. METRICS (MetricsCollector) observe the derived outputs

    This separation clarifies:
    - What ParameterSweeper should vary (fundamentals)
    - What MetricsCollector should observe (derived metrics)
    - Why state variables should never be directly manipulated

  diagram: |
    ┌─────────────────────────────────────────────────────────────────────────┐
    │                         FUNDAMENTALS (Level 1)                          │
    │  GameDefines: extraction_efficiency, subsistence, repression,           │
    │               organization, initial wealth, loss_aversion_lambda, k     │
    │  Location: src/babylon/config/defines.py                                │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │                           SYSTEMS (Level 2)                             │
    │  ImperialRentSystem, SurvivalSystem, SolidaritySystem,                  │
    │  ConsciousnessSystem, ContradictionSystem, TerritorySystem              │
    │  Location: src/babylon/engine/systems/                                  │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │                       STATE VARIABLES (Level 2b)                        │
    │  WorldState: wealth[], consciousness[], tension[], imperial_rent_pool   │
    │  Location: src/babylon/models/world_state.py                            │
    └─────────────────────────────────────────────────────────────────────────┘
                                        │
                                        ▼
    ┌─────────────────────────────────────────────────────────────────────────┐
    │                       DERIVED METRICS (Level 3)                         │
    │  MetricsCollector: pool_ratio, consciousness_gap, wealth_gap,           │
    │                    global_tension, P(S|A), P(S|R), percolation_ratio    │
    │  Location: src/babylon/engine/observers/metrics.py                      │
    └─────────────────────────────────────────────────────────────────────────┘

  levels:
    level_1_fundamentals:
      description: "TRUE FUNDAMENTALS - Independent variables, simulation's atoms"
      location: "src/babylon/config/defines.py"
      examples:
        - "economy.extraction_efficiency - Determines imperial rent (Phi)"
        - "economy.initial_rent_pool - Sets economic scale"
        - "survival.default_subsistence - P(S|A) baseline"
        - "survival.default_repression - P(S|R) denominator"
        - "behavioral.loss_aversion_lambda - Kahneman-Tversky constant"
      principle: "ParameterSweeper varies THESE"

    level_2_systems:
      description: "TRANSFORMATION LAYER - Pure functions on state"
      location: "src/babylon/engine/systems/"
      function: "step(WorldState, config, context, defines) → WorldState"
      constraint: "No side effects, no DB I/O, no external state"

    level_2b_state:
      description: "STATE VARIABLES - Evolve over time via Systems"
      location: "src/babylon/models/world_state.py"
      examples:
        - "wealth: Previous + inflows - outflows"
        - "consciousness: dΨ = k(1 - W_c/V_c) - λΨ"
        - "tension: Accumulates from wealth gaps"
      constraint: "Never manipulate directly - let Systems transform them"

    level_3_metrics:
      description: "DERIVED METRICS - Observations computed from state"
      location: "src/babylon/models/metrics.py"
      examples:
        - "pool_ratio = imperial_rent_pool / initial_pool"
        - "consciousness_gap = P_w.Ψ - C_w.Ψ"
        - "global_tension = avg(EXPLOITATION.tension)"
        - "P(S|A) = σ(W - S)"
      principle: "MetricsCollector observes THESE"

  minimal_basis:
    description: "The truly irreducible parameters from MLM-TW theory"
    parameters:
      - "Initial wealth distribution (4 values)"
      - "Extraction rate (how fast imperial rent flows)"
      - "Subsistence threshold (P(S|A) collapse point)"
      - "Repression capacity (state violence)"
      - "Solidarity edge weights (consciousness transmission)"
    insight: |
      Everything else derives from these + time. This is the simulation's
      equivalent of physics' Planck constants (c, h, G).

  architecture_principle: |
    CORRECT USAGE:
    - ParameterSweeper: Vary FUNDAMENTALS (GameDefines), observe METRICS
    - MetricsCollector: Read-only observation of DERIVED METRICS
    - Systems: Transform state according to formulas

    ANTI-PATTERN:
    - Directly manipulating state variables (bypasses Systems)
    - Hardcoding metrics extraction (creates parallel paths)
    - Mixing fundamental and derived in same interface

# =============================================================================
# EXTENSION POINTS
# =============================================================================

extension_points:

  new_entity_type:
    steps:
      - "Add schema to schemas/entities/"
      - "Add collection schema to schemas/collections/"
      - "Add JSON data file to data/"
      - "Add Pydantic model to data/models/"
      - "Register in entity_registry.py"

  new_game_mechanic:
    steps:
      - "Add formula to systems/formulas.py"
      - "Register formula in formula_registry.py FormulaRegistry.default()"
      - "Add tests with @pytest.mark.math"
      - "Create new System class in engine/systems/ if needed"
      - "Document in ai-docs/ontology.yaml if new concept"

  new_ai_capability:
    steps:
      - "Add to rag/ layer only"
      - "Query existing state, never modify directly"
      - "Add @pytest.mark.ai tests (separate from logic tests)"

# =============================================================================
# CROSS-CUTTING INFRASTRUCTURE
# =============================================================================

infrastructure:

  logging:
    summary: "Python stdlib logging with custom enhancements (no dependencies)"
    related_docs:
      - "ai-docs/logging-architecture.yaml (comprehensive spec)"
      - "ADR018_logging_strategy in decisions.yaml"
    principle: "Dual output: human console + machine JSON files"
    key_components:
      custom_formatter: "JSONFormatter in src/babylon/utils/log.py (planned)"
      custom_level: "TRACE (value=5) for ultra-verbose debugging"
      rotation: "RotatingFileHandler (10MB main, 5MB errors)"
    layer_loggers:
      ledger: "babylon.data.* - Database/persistence events"
      topology: "babylon.engine.* - Graph/tick events"
      archive: "babylon.rag.* - Embedding/query events"
      superstructure: "babylon.ai.* - Narrative/LLM events"

  exceptions:
    summary: "Unified exception hierarchy (10 classes)"
    related_docs:
      - "ai-docs/exceptions-architecture.yaml (comprehensive spec)"
      - "ADR019_exception_hierarchy in decisions.yaml"
    location: "src/babylon/utils/exceptions.py"
    hierarchy: |
      BabylonError (base)
      ├── InfrastructureError (retryable I/O)
      │   ├── DatabaseError
      │   └── StorageError
      ├── ValidationError (bad input)
      │   └── ConfigurationError
      ├── SimulationError (fatal engine)
      │   └── TopologyError
      └── ObserverError (non-fatal AI)
          └── LLMError
    principle: "Log at handling boundary, not at raise site"
