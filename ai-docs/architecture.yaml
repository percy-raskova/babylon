# Babylon System Architecture
# How the pieces fit together

meta:
  version: "3.2.0"
  updated: "2025-12-09"
  status: "Phase 3 in progress (983+ tests, Observer + RAG complete, LLM next)"

# =============================================================================
# THE EMBEDDED TRINITY
# =============================================================================

core_architecture:
  name: "The Embedded Trinity"
  principle: "Three-layer local system, no external servers"

  layers:
    ledger:
      purpose: "Rigid, material state"
      technology: "SQLite + Pydantic"
      location: "src/babylon/data/"
      contains:
        - "JSON data files (17 entity collections)"
        - "database.py (SQLAlchemy session)"
        - "Pydantic models for validation"
      data_flow: "Read at startup, modified by game events, persisted on save"

    topology:
      purpose: "Fluid, relational state"
      technology: "NetworkX (in-memory graph)"
      locations:
        primary: "src/babylon/models/world_state.py (to_graph/from_graph)"
        formulas: "src/babylon/systems/formulas.py"
        engine: "src/babylon/engine/simulation_engine.py"
      contains:
        - "WorldState.to_graph() - DiGraph of entities and relationships"
        - "Relationship edges (EXPLOITATION, SOLIDARITY, REPRESSION)"
        - "Node attributes (wealth, ideology, organization, p_*)"
        - "Edge attributes (value_flow, tension)"
      data_flow: "WorldState converted to graph for step(), then back"
      key_insight: "Graph + Math = History (ADR011)"

    archive:
      purpose: "Semantic history and theory"
      technology: "ChromaDB + embeddings"
      location: "src/babylon/rag/"
      contains:
        - "Historical events"
        - "Theoretical texts (MLM-TW corpus) - NOT YET POPULATED"
        - "Past game states for narrative"
      data_flow: "AI queries for context, generates narrative from state changes"
      key_insight: "AI observes and narrates, never controls mechanics"
      current_status: "Infrastructure complete, ChromaDB empty (no corpus ingested)"

    superstructure:
      purpose: "AI narrative layer (Phase 3)"
      technology: "Observer Pattern + LLM Provider"
      location: "src/babylon/ai/"
      contains:
        - "NarrativeDirector - SimulationObserver implementation"
        - "DialecticalPromptBuilder - context hierarchy assembly"
        - "LLM Provider (planned) - Claude/Ollama/DeepSeek abstraction"
      data_flow: "Observes state → Queries RAG → Builds prompt → Calls LLM → Outputs narrative"
      key_insight: "Read-only access to simulation state (ADR003)"
      current_status: "Observer + RAG complete, LLM integration pending (Sprint 3.3)"

# =============================================================================
# DIRECTORY STRUCTURE
# =============================================================================

directory_map:
  src/babylon/:
    config/: "BaseConfig, environment variables, logging setup"
    core/:
      purpose: "Legacy topology layer (partially deprecated)"
      status: "economy.py and politics.py DELETED per ADR011"
      key_files:
        - "contradiction.py: Legacy ContradictionAnalysis"
        - "entity.py: Base Entity class"
      note: "See engine/ and systems/ for Phase 2+ implementation"

    engine/:
      purpose: "Simulation engine - the Phase 2 game loop"
      key_files:
        - "simulation_engine.py: SimulationEngine class + step() function"
        - "services.py: ServiceContainer (dependency injection)"
        - "event_bus.py: EventBus (publish/subscribe)"
        - "formula_registry.py: FormulaRegistry (12 formulas)"
        - "database.py: DatabaseConnection (SQLAlchemy)"
        - "simulation.py: Simulation facade class"
        - "factories.py: create_proletariat(), create_bourgeoisie()"
        - "scenarios.py: Factory functions for test scenarios"
        - "history_formatter.py: format_class_struggle_history()"
      subdirs:
        systems/:
          purpose: "Modular System implementations"
          files:
            - "protocol.py: System protocol with step(graph, services, context)"
            - "economic.py: ImperialRentSystem"
            - "ideology.py: ConsciousnessSystem"
            - "survival.py: SurvivalSystem"
            - "contradiction.py: ContradictionSystem"
        history/:
          purpose: "State persistence and undo/redo"
          files:
            - "models.py: HistoryStack, Checkpoint, CheckpointConfig"
            - "stack.py: push_state, undo, redo, prune_history"
            - "io.py: save_state, load_state, atomic writes"
            - "auto_checkpoint.py: AutoCheckpointer"
      status: "IMPLEMENTED (150+ tests)"

    models/:
      purpose: "Pydantic models for the simulation"
      key_files:
        - "world_state.py: Immutable state snapshot with NetworkX integration"
        - "config.py: SimulationConfig (frozen, 11 parameters)"
        - "types.py: Constrained types (Probability, Currency, Ideology, etc.)"
        - "enums.py: StrEnum definitions (SocialRole, EdgeType, etc.)"
      subdirs:
        entities/:
          purpose: "Game entity models"
          files:
            - "social_class.py: SocialClass (Phase 1 node)"
            - "relationship.py: Relationship (Phase 1 edge)"
            - "effect.py, contradiction.py, trigger.py: Supporting models"
        components/:
          purpose: "Component system (Material Ontology)"
          files:
            - "base.py: Component protocol"
            - "material.py: MaterialComponent (wealth, resources, means_of_production)"
            - "vitality.py: VitalityComponent (population, subsistence_needs)"
            - "spatial.py: SpatialComponent (location_id, mobility)"
            - "ideological.py: IdeologicalComponent (alignment, adherence)"
            - "organization.py: OrganizationComponent (cohesion, cadre_level)"
      status: "IMPLEMENTED (200+ tests)"
    data/:
      purpose: "Ledger layer - persistent state"
      key_files:
        - "entity_registry.py: Entity lookup"
      subdirs:
        game/:
          purpose: "Game data JSON files"
          files: "17 entity collection JSON files (characters, factions, classes, etc.)"
        xml/:
          purpose: "Legacy XML (reference only)"
    schemas/:
      purpose: "JSON Schema validation"
      structure:
        - "core/common.schema.json: Shared $defs"
        - "core/base.schema.json: Metadata envelope"
        - "entities/*.schema.json: 17 entity schemas"
        - "collections/*.schema.json: 17 collection schemas"
    ai/:
      purpose: "Superstructure layer - AI narrative generation (Phase 3)"
      key_files:
        - "director.py: NarrativeDirector (SimulationObserver)"
        - "prompt_builder.py: DialecticalPromptBuilder (context hierarchy)"
        - "llm_provider.py: LLM abstraction (PLANNED - Sprint 3.3)"
      status: "IMPLEMENTED (59 tests)"
      data_flow: |
        1. NarrativeDirector.on_tick(prev, new) called by Simulation
        2. Detect new events in WorldState.event_log
        3. Query RagPipeline for historical/theoretical context
        4. Build context block via DialecticalPromptBuilder
        5. Call LLM provider (NOT YET IMPLEMENTED)
        6. Output narrative text

    rag/:
      purpose: "Archive layer - semantic memory"
      key_files:
        - "rag_pipeline.py: RagPipeline (query interface)"
        - "retrieval.py: QueryResponse, QueryResult models"
        - "embeddings.py: Embedding generation"
        - "chunker.py: Document chunking"
        - "chroma_manager.py: ChromaDB client management"
      status: "Infrastructure complete, NO DATA POPULATED"
      note: "ChromaDB collections are empty - no corpus ingested yet"

    systems/:
      purpose: "Game systems implementation"
      key_files:
        - "formulas.py: Mathematical core"
        - "contradiction_analysis.py: Dialectical engine"
    metrics/: "Performance and gameplay metrics"
    utils/: "Shared utilities, exceptions"

  tools/:
    purpose: "CLI utilities"
    key_files:
      - "migrate_xml_to_json.py: Legacy migration"
      - "validate_schemas.py: Schema validation"

  tests/:
    structure:
      - "unit/: Fast, deterministic tests"
      - "fixtures/: Test data"
      - "mocks/: Test doubles"
    markers:
      - "math: Pure formula tests"
      - "ledger: State tests"
      - "topology: Graph tests"
      - "integration: I/O tests"
      - "ai: Slow AI evals"

  brainstorm/: "Ideas not yet ready for implementation"
  ai-docs/: "Machine-readable docs for AI assistants"

# =============================================================================
# DATA FLOW
# =============================================================================

data_flows:

  startup:
    steps:
      - "Load JSON data files from src/babylon/data/"
      - "Validate against schemas"
      - "Build Pydantic models"
      - "Construct NetworkX graph (Topology)"
      - "Initialize ChromaDB connection (Archive)"

  game_turn:
    implementation: "step(WorldState, SimulationConfig) → WorldState"
    location: "src/babylon/engine/simulation_engine.py"
    architecture:
      engine: "SimulationEngine.run_tick(graph, services, context)"
      systems:
        - "1. ImperialRentSystem - Extract imperial rent from exploitation edges"
        - "2. ConsciousnessSystem - Apply consciousness drift (dΨ/dt)"
        - "3. SurvivalSystem - Update P(S|A) and P(S|R)"
        - "4. ContradictionSystem - Accumulate tension, publish rupture events"
      services:
        container: "ServiceContainer aggregates all dependencies"
        config: "SimulationConfig with all formula coefficients"
        formulas: "FormulaRegistry with 12 hot-swappable formulas"
        event_bus: "EventBus for event publishing"
        database: "DatabaseConnection for persistence"
    steps:
      - "1. Convert WorldState to NetworkX DiGraph"
      - "2. Create ServiceContainer with config"
      - "3. Run all 4 Systems in historical materialist order"
      - "4. Convert graph back to new WorldState"
      - "5. Increment tick and return new state"
    phase_3_additions:
      - "AI generates narrative from changes (Observer Pattern)"
      - "More event types (wealth_transfer, ideology_drift, etc.)"

  ai_narrative:
    principle: "AI is observer, not controller (ADR003)"
    status: "Partially implemented - LLM call missing"
    implementation:
      observer: "NarrativeDirector implements SimulationObserver"
      context: "DialecticalPromptBuilder assembles context hierarchy"
      retrieval: "RagPipeline queries ChromaDB (currently empty)"
      llm: "NOT YET IMPLEMENTED - Sprint 3.3"
    steps:
      - "Simulation.step() calls observer.on_tick(prev_state, new_state)"
      - "NarrativeDirector detects new events in event_log"
      - "Query RagPipeline for relevant history/theory"
      - "Build context block: Material Conditions → RAG Context → Events"
      - "Call LLM provider (MISSING)"
      - "Output narrative text"
      - "Never modify game mechanics"
    gaps_identified:
      - "ChromaDB has no corpus data (RAG returns empty)"
      - "Only ContradictionSystem emits events (rupture only)"
      - "No LLM client implementation"
      - "No CLI runner for vertical slice demo"

# =============================================================================
# KEY INTERFACES
# =============================================================================

interfaces:

  entity_to_ledger:
    pattern: "Pydantic models validated against JSON Schema"
    example: "Faction model → factions.json → factions.schema.json"

  ledger_to_topology:
    pattern: "JSON data → NetworkX nodes/edges"
    example: "faction.dialectical_relationships → graph edges"

  topology_to_archive:
    pattern: "State changes → ChromaDB queries → narrative"
    example: "Contradiction intensified → find similar historical events → generate description"

# =============================================================================
# EXTENSION POINTS
# =============================================================================

extension_points:

  new_entity_type:
    steps:
      - "Add schema to schemas/entities/"
      - "Add collection schema to schemas/collections/"
      - "Add JSON data file to data/"
      - "Add Pydantic model to data/models/"
      - "Register in entity_registry.py"

  new_game_mechanic:
    steps:
      - "Add formula to systems/formulas.py"
      - "Register formula in formula_registry.py FormulaRegistry.default()"
      - "Add tests with @pytest.mark.math"
      - "Create new System class in engine/systems/ if needed"
      - "Document in ai-docs/ontology.yaml if new concept"

  new_ai_capability:
    steps:
      - "Add to rag/ layer only"
      - "Query existing state, never modify directly"
      - "Add @pytest.mark.ai tests (separate from logic tests)"

# =============================================================================
# CROSS-CUTTING INFRASTRUCTURE
# =============================================================================

infrastructure:

  logging:
    summary: "Python stdlib logging with custom enhancements (no dependencies)"
    related_docs:
      - "ai-docs/logging-architecture.yaml (comprehensive spec)"
      - "ADR018_logging_strategy in decisions.yaml"
    principle: "Dual output: human console + machine JSON files"
    key_components:
      custom_formatter: "JSONFormatter in src/babylon/utils/log.py (planned)"
      custom_level: "TRACE (value=5) for ultra-verbose debugging"
      rotation: "RotatingFileHandler (10MB main, 5MB errors)"
    layer_loggers:
      ledger: "babylon.data.* - Database/persistence events"
      topology: "babylon.engine.* - Graph/tick events"
      archive: "babylon.rag.* - Embedding/query events"
      superstructure: "babylon.ai.* - Narrative/LLM events"

  exceptions:
    summary: "Unified exception hierarchy (10 classes)"
    related_docs:
      - "ADR002_exception_codes in decisions.yaml"
    location: "src/babylon/utils/exceptions.py"
    hierarchy: |
      BabylonError (base)
      ├── InfrastructureError (retryable I/O)
      │   ├── DatabaseError
      │   └── StorageError
      ├── ValidationError (bad input)
      │   └── ConfigurationError
      ├── SimulationError (fatal engine)
      │   └── TopologyError
      └── ObserverError (non-fatal AI)
          └── LLMError
    principle: "Log at handling boundary, not at raise site"
