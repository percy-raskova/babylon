# Parameter Analysis Specification
# Comprehensive simulation analysis for balance tuning and theory validation

meta:
  version: "2.0.0"
  created: "2025-12-11"
  updated: "2025-12-30"
  purpose: "Define methodology for deep parameter analysis and observation recording"
  status: "ACTIVE"
  primary_tool: "tools/tune_agent.py (Optuna-based Bayesian Optimization)"
  legacy_tools:
    - "tools/parameter_analysis.py (trace/sweep commands)"
    - "tools/tune_parameters.py (manual inspection only)"
    - "tools/landscape_analysis.py (2D grid search)"
  related:
    - "ai-docs/balance-tuning.yaml (findings registry)"
    - "ai-docs/formulas-spec.yaml (formula definitions)"
    - "ai-docs/tuning-standard.md (tuning workflow guide)"
    - "brainstorm/plans/parameter-analysis-plan.md (implementation plan)"

# =============================================================================
# METHODOLOGY EVOLUTION
# =============================================================================

methodology:
  current_approach: "Bayesian Optimization"
  previous_approach: "Grid Search / Parameter Sweep"
  migration_date: "2025-12-30"

  why_bayesian:
    problem_with_grid_search: |
      Grid search is computationally expensive for Babylon's high-dimensional
      parameter space. A 5-parameter grid with 10 values each requires 100,000
      simulations. With 52-tick simulations, this becomes impractical.

    babylon_specific_challenges:
      - name: "Discontinuous Failure States (The Cliff)"
        description: |
          Babylon has sudden death mechanics where the Comprador (P_c) can
          collapse from wealth=8.0 to wealth=0.0 in a single tick. This creates
          sharp discontinuities in the objective landscape that gradient descent
          cannot navigate.

      - name: "High-Dimensional Interactions"
        description: |
          Parameters interact non-linearly. extraction_efficiency × comprador_cut
          produces emergent behaviors not predictable from individual sweeps.

      - name: "Computational Cost"
        description: |
          Each simulation is O(n) where n=ticks. Running 52-tick simulations
          at grid-search scale (10^5 evaluations) is prohibitively expensive.

    why_tpe_not_gradient:
      description: "Tree-structured Parzen Estimator vs Gradient-Based Methods"
      reasons:
        - "No gradient available (simulation is a black box)"
        - "Non-convex landscape with many local minima"
        - "Discontinuous 'cliff' failures defeat gradient estimation"
        - "TPE handles mixed continuous/discrete parameters"

  algorithm:
    name: "Tree-structured Parzen Estimator (TPE)"
    library: "Optuna"
    description: |
      TPE models the objective function as two probability distributions:
      P(x|y < y*) and P(x|y >= y*) where y* is a threshold. It samples from
      regions that historically produced good results while exploring.

    hyperparameters:
      n_trials: 100-500
      n_startup_trials: 10
      seed: 42
      multivariate: true

  pruning:
    name: "Hyperband Pruning (Successive Halving)"
    description: |
      Aggressively terminates unpromising trials early. If a simulation shows
      Comprador death before tick 10, there's no value in running to tick 52.
      This provides 5-10x speedup over exhaustive evaluation.

    babylon_specific_rules:
      - condition: "P_c wealth < 0.01 before tick 10"
        action: "Prune trial immediately"
      - condition: "P_w wealth < 0.001 before tick 15"
        action: "Prune trial immediately"
      - condition: "Rent pool < 10.0 before tick 20"
        action: "Prune trial (imperial circuit broken)"

  goal:
    name: "Maximize Stability + Complexity (The Playable Boundary)"
    anti_goal: "NOT just maximize wealth or survival time"

    objective_function: |
      Score = w1 * ticks_survived +
              w2 * min(rent_pool, initial_pool) +
              w3 * consciousness_variance +
              w4 * survival_margin

    components:
      ticks_survived:
        weight: 0.4
        description: "How long the simulation runs before failure"

      rent_pool_health:
        weight: 0.3
        description: "Imperial rent pool should stay in 'goldilocks zone' (20-80% of initial)"

      consciousness_variance:
        weight: 0.2
        description: "Higher variance = more interesting dynamics (not flat)"

      survival_margin:
        weight: 0.1
        description: "How close P_w gets to death threshold (closer = more dramatic)"

    edge_of_chaos: |
      The "playable boundary" is where the simulation is challenging but not
      impossible. Too easy = boring. Too hard = frustrating. The objective
      function is tuned to find this edge.

  computational_efficiency:
    primary_driver: true
    description: |
      The shift to Bayesian Optimization is driven primarily by computational
      efficiency. TPE + Hyperband can find optimal parameters in 100-200 trials
      that would require 10,000+ trials with grid search.

    expected_speedup: "10-50x vs exhaustive grid search"

    optuna_dashboard:
      description: "Visual analysis of optimization history"
      features:
        - "Pareto front visualization for multi-objective"
        - "Parameter importance analysis"
        - "Slice plots for individual parameter effects"
        - "Trial history and pruning statistics"

# =============================================================================
# MOTIVATION
# =============================================================================

motivation:
  problem: |
    Current tune_parameters.py only tells us "periphery died at tick 27".
    We need to see the FULL STORY:
    - How wealth flows between all 4 entities over time
    - When consciousness rises/falls and WHY
    - The exact moment P(S|R) crosses P(S|A)
    - How the imperial rent pool grows or shrinks

  insight: |
    The Imperial Collapse Dynamic discovery shows emergent behavior exists.
    But we can only find it by watching trajectories, not endpoints.
    "Greedy empires collapse" required seeing wealth drain RATE, not just death tick.

  goal: |
    Enable rich observational data collection for:
    1. Parameter tuning (find playable boundaries)
    2. Theory validation (does model match MLM-TW predictions?)
    3. Emergent behavior discovery (what dynamics arise?)

# =============================================================================
# TOOL SPECIFICATION
# =============================================================================

tool_specification:

  name: "parameter_analysis.py"
  location: "tools/parameter_analysis.py"

  commands:

    trace:
      description: "Single simulation with full time-series output"
      purpose: "Deep dive into one parameter configuration"
      usage: |
        python tools/parameter_analysis.py trace \
          --param economy.extraction_efficiency=0.2 \
          --ticks 50 \
          --csv results/trace_0.2.csv
      output: "CSV with one row per tick, all entity/edge states"

    sweep:
      description: "Parameter sweep with summary statistics"
      purpose: "Find boundaries and transitions"
      usage: |
        python tools/parameter_analysis.py sweep \
          --param economy.extraction_efficiency \
          --start 0.1 --end 0.5 --step 0.05 \
          --csv results/extraction_sweep.csv
      output: "CSV with one row per parameter value, summary metrics"

    grid:
      description: "2D parameter grid search"
      purpose: "Find interaction effects between parameters"
      usage: |
        python tools/parameter_analysis.py grid \
          --param1 economy.extraction_efficiency --range1 0.1,0.4,0.1 \
          --param2 economy.super_wage_rate --range2 0.1,0.5,0.1 \
          --csv results/grid_search.csv
      output: "CSV with param1, param2, and outcome metrics"

# =============================================================================
# DATA SCHEMA
# =============================================================================

data_schema:

  entities_tracked:
    P_w:
      id: "C001"
      name: "Periphery Worker"
      metrics:
        - wealth
        - consciousness
        - organization
        - p_acquiescence    # P(S|A)
        - p_revolution      # P(S|R)
        - is_dead           # wealth <= 0.001

    P_c:
      id: "C002"
      name: "Comprador"
      metrics:
        - wealth

    C_b:
      id: "C003"
      name: "Core Bourgeoisie"
      metrics:
        - wealth
        - tribute_inflow    # imperial rent received this tick

    C_w:
      id: "C004"
      name: "Labor Aristocracy"
      metrics:
        - wealth
        - consciousness
        - wages_received
        - is_labor_aristocrat  # W > V check

  edges_tracked:
    exploitation:
      type: "EXPLOITATION"
      direction: "P_w → P_c"
      metrics:
        - tension
        - rent_extracted

    tribute:
      type: "TRIBUTE"
      direction: "P_c → C_b"
      metrics:
        - value_transferred

    wages:
      type: "WAGES"
      direction: "C_b → C_w"
      metrics:
        - wages_paid

    solidarity:
      type: "SOLIDARITY"
      direction: "P_w ↔ C_w"
      metrics:
        - solidarity_strength
        - transmission_delta
      note: "May not exist in all scenarios"

  derived_metrics:
    - crossover_tick: "First tick where P(S|R) > P(S|A)"
    - imperial_rent_cumulative: "Total extraction over simulation"
    - system_wealth_total: "Sum of all entity wealth (conservation check)"
    - labor_aristocracy_ratio: "C_w wages / C_w value produced"

  csv_schema_trace: |
    tick,p_w_wealth,p_w_consciousness,p_w_psa,p_w_psr,p_w_dead,
    p_c_wealth,c_b_wealth,c_b_tribute_inflow,
    c_w_wealth,c_w_consciousness,c_w_wages,c_w_is_aristocrat,
    exploitation_tension,exploitation_rent,tribute_flow,wages_paid,
    solidarity_strength,solidarity_delta

  csv_schema_sweep: |
    param_value,ticks_survived,max_tension,outcome,
    final_p_w_wealth,final_c_b_wealth,final_c_w_wealth,
    crossover_tick,cumulative_rent,peak_consciousness

  csv_schema_grid: |
    param1_value,param2_value,ticks_survived,outcome,
    final_p_w_wealth,final_c_b_wealth,crossover_tick

# =============================================================================
# KEY QUESTIONS TO ANSWER
# =============================================================================

research_questions:

  imperial_dynamics:
    - question: "At what extraction rate does C_b start LOSING wealth?"
      hypothesis: "High extraction kills periphery before rent accumulates"
      metric: "c_b_wealth trajectory over time"

    - question: "Is there a 'Goldilocks zone' for sustainable empire?"
      hypothesis: "Some extraction rate keeps periphery barely alive indefinitely"
      metric: "p_w_wealth stable above death threshold"

    - question: "How does super_wage_rate affect imperial stability?"
      hypothesis: "Higher super-wages drain C_b faster but keep C_w loyal"
      metric: "Grid search extraction × super_wage"

  consciousness_dynamics:
    - question: "When does Labor Aristocracy consciousness start rising?"
      hypothesis: "Only when super-wages drop below value produced"
      metric: "c_w_consciousness trajectory vs c_w_wages"

    - question: "What triggers revolutionary crossover in periphery?"
      hypothesis: "P(S|R) > P(S|A) when wealth drops AND organization rises"
      metric: "crossover_tick vs organization level"

  fascist_bifurcation:
    - question: "Without solidarity edges, does agitation produce fascism?"
      hypothesis: "Same material conditions, different outcomes based on solidarity"
      metric: "Compare scenarios with solidarity=0 vs solidarity>0"
      reference: "ADR016_fascist_bifurcation"

  system_behavior:
    - question: "Is total system wealth conserved?"
      hypothesis: "Wealth transfers, doesn't create/destroy (closed system)"
      metric: "system_wealth_total should be constant"

    - question: "What feedback loops exist?"
      hypothesis: |
        - Extraction → wealth loss → consciousness rise → resistance → less extraction
        - Super-wages → false consciousness → less resistance → more extraction
      metric: "Correlation analysis in time-series data"

# =============================================================================
# PARAMETERS TO ANALYZE
# =============================================================================

parameters_to_analyze:

  high_priority:
    - path: "economy.extraction_efficiency"
      description: "Alpha in Φ = α × W × (1-Ψ)"
      current_default: 0.8
      recommended_range: [0.05, 0.50]
      known_findings: "Boundary at 0.25, Imperial Collapse Dynamic"

    - path: "economy.super_wage_rate"
      description: "Fraction of tribute paid as super-wages"
      current_default: "unknown - check GameDefines"
      hypothesis: "Higher = more C_w loyalty but faster C_b drain"

    - path: "economy.base_subsistence"
      description: "S in P(S|A) sigmoid"
      hypothesis: "Higher = earlier death, faster collapse"

  medium_priority:
    - path: "consciousness.drift_sensitivity_k"
      description: "k in dΨ/dt = k(1-W/V) - λΨ"
      hypothesis: "Higher = faster consciousness change"

    - path: "consciousness.decay_lambda"
      description: "λ in consciousness drift formula"
      hypothesis: "Higher = consciousness fades faster without material basis"

    - path: "solidarity.transmission_coefficient"
      description: "σ in solidarity transmission"
      hypothesis: "Critical for Fascist Bifurcation mechanic"

  interaction_effects:
    - pair: ["extraction_efficiency", "super_wage_rate"]
      hypothesis: "High extraction + high super-wages = unsustainable"

    - pair: ["extraction_efficiency", "base_subsistence"]
      hypothesis: "Both affect time-to-death, may compound"

# =============================================================================
# ARCHITECTURAL ANALYSIS (2025-12-25)
# =============================================================================
# Understanding the relationship between parameter sweeping and metrics collection

architecture_analysis:
  date: "2025-12-25"

  coupling_problem:
    status: "DESIGN DEBT IDENTIFIED"
    description: |
      parameter_analysis.py and MetricsCollector implement PARALLEL data collection
      paths. When new metrics are added to TickMetrics, parameter_analysis.py does
      NOT automatically receive them because it has its own collect_tick_data().

    current_state:
      dashboard_path:
        uses: "MetricsCollector (observer pattern)"
        method: "collector.to_csv_rows()"
        auto_updates: true
      sweeper_path:
        uses: "collect_tick_data() (manual extraction)"
        method: "Direct WorldState field access"
        auto_updates: false

    evidence:
      location: "tools/parameter_analysis.py:108-173"
      code_pattern: |
        # Duplicates MetricsCollector extraction logic
        row["p_w_wealth"] = float(p_w.wealth)
        row["p_w_consciousness"] = float(p_w.ideology.class_consciousness)
        # ... manually lists each field

    impact: |
      Phase 4.1B added current_super_wage_rate, current_repression_level, pool_ratio,
      consciousness_gap, wealth_gap to TickMetrics. Dashboard sees these automatically.
      ParameterSweeper does NOT see them without code changes to collect_tick_data().

    recommended_fix:
      description: "Refactor parameter_analysis.py to use MetricsCollector"
      priority: "Phase 4.2 or later"
      pattern: |
        from babylon.engine.observers.metrics import MetricsCollector

        collector = MetricsCollector(mode="batch")
        collector.on_simulation_start(state, config)
        for tick in range(max_ticks):
            prev = state
            state = step(state, config, context, defines)
            collector.on_tick(prev, state)

        return collector.to_csv_rows()  # Automatic, includes ALL metrics

  fundamental_vs_derived:
    description: |
      In physics, we have Planck constants (c, h, G) from which everything derives.
      What are our simulation's "Planck constants"? Understanding this hierarchy
      clarifies what ParameterSweeper should vary vs what MetricsCollector should observe.

    causal_hierarchy:
      level_1_fundamentals:
        description: "TRUE FUNDAMENTALS (Independent Variables) - The simulation's atoms"
        location: "src/babylon/config/defines.py (GameDefines)"
        parameters:
          extraction_efficiency:
            path: "economy.extraction_efficiency"
            type: "float [0, 1]"
            why_fundamental: "Determines Phi (imperial rent) - core of MLM-TW model"
          initial_rent_pool:
            path: "economy.initial_rent_pool"
            type: "Currency"
            why_fundamental: "Sets economic scale, pool_ratio reference point"
          subsistence:
            path: "survival.default_subsistence"
            type: "float [0, 1]"
            why_fundamental: "Sets P(S|A) baseline - material survival threshold"
          default_repression:
            path: "survival.default_repression"
            type: "float [0, 1]"
            why_fundamental: "Sets P(S|R) denominator - state violence capacity"
          default_organization:
            path: "survival.default_organization"
            type: "float [0, 1]"
            why_fundamental: "Sets P(S|R) numerator - collective action capacity"
          steepness_k:
            path: "survival.steepness_k"
            type: "float > 0"
            why_fundamental: "Shape of P(S|A) sigmoid - how sharply survival drops"
          loss_aversion_lambda:
            path: "behavioral.loss_aversion_lambda"
            type: "float > 0"
            why_fundamental: "Kahneman-Tversky constant - behavioral economics baseline"
          initial_wealth_distribution:
            components: ["initial.worker_wealth", "initial.owner_wealth"]
            why_fundamental: "Starting material conditions - 4 entity starting points"

      level_2_dynamics:
        description: "DERIVED DYNAMICS (State Variables) - Evolve over time from fundamentals"
        examples:
          - "wealth: Previous + inflows - outflows (accounting identity)"
          - "consciousness: dΨ = k(1 - W_c/V_c) - λΨ (differential equation)"
          - "tension: Accumulates from wealth gaps (difference equation)"
          - "current_super_wage_rate: Bourgeois heuristic output"
          - "current_repression_level: Bourgeois heuristic output"

      level_3_metrics:
        description: "DERIVED METRICS (Observations) - Computed from state for analysis"
        location: "src/babylon/models/metrics.py (TickMetrics)"
        examples:
          - "pool_ratio = imperial_rent_pool / initial_pool"
          - "consciousness_gap = P_w.Ψ - C_w.Ψ"
          - "wealth_gap = C_b.W - P_w.W"
          - "global_tension = avg(EXPLOITATION.tension)"
          - "P(S|A) = σ(W - S)"
          - "P(S|R) = O / (R + base)"
          - "percolation_ratio = L_max / N"

    minimal_basis:
      description: "The truly irreducible parameters from MLM-TW theory"
      parameters:
        - "Initial wealth distribution (4 values)"
        - "Extraction rate (how fast imperial rent flows)"
        - "Subsistence threshold (below this, P(S|A) collapses)"
        - "Repression capacity (state violence as material force)"
        - "Solidarity edge weights (infrastructure for consciousness transmission)"
      insight: |
        Everything else derives from these + time:
        - Consciousness flows through solidarity edges
        - Tension accumulates from wealth gaps
        - Pool depletes from extraction
        - Wage/repression adjusts from pool ratio
        - Phase transitions emerge from percolation

    architecture_principle: |
      ParameterSweeper should:
        - INPUT: Vary FUNDAMENTALS (via GameDefines injection)
        - OUTPUT: Observe DERIVED METRICS (via MetricsCollector)
        - NEVER: Directly manipulate state variables

      Current architecture status:
        - GameDefines ✅ - Correctly stores fundamentals
        - Systems ✅ - Correctly compute derived dynamics
        - MetricsCollector ✅ - Correctly observes derived metrics
        - ParameterSweeper ❌ - Bypasses MetricsCollector, breaks abstraction

# =============================================================================
# IMPLEMENTATION PHASES
# =============================================================================

implementation:

  phase_1:
    name: "Trace Command"
    status: "COMPLETE"
    completed: "2025-12-11"
    deliverables:
      - "trace subcommand with full time-series CSV"
      - "Track all 4 entities"
      - "Track key edges"
      - "Derived metrics calculation"
    tests:
      - "test_trace_produces_csv"
      - "test_trace_tracks_all_entities"
      - "test_trace_calculates_derived_metrics"
    validation:
      command: "mise run analyze-trace"
      output: "results/trace.csv"
      last_run: "2025-12-11"
      result: "16 ticks recorded (early termination due to wealth depletion)"

  phase_2:
    name: "Sweep Command Enhancement"
    status: "COMPLETE"
    completed: "2025-12-11"
    deliverables:
      - "sweep subcommand with rich summary CSV"
      - "More metrics than current tune_parameters.py"
      - "Crossover tick detection"
    tests:
      - "test_sweep_detects_crossover"
      - "test_sweep_tracks_all_entities"
    validation:
      command: "mise run analyze-sweep"
      output: "results/sweep.csv"
      last_run: "2025-12-11"
      result: "10 parameter values tested (0.05-0.50 step 0.05)"

  phase_3:
    name: "Grid Search"
    status: "PLANNED"
    deliverables:
      - "grid subcommand for 2D parameter space"
      - "Heatmap-ready CSV output"
    tests:
      - "test_grid_iterates_all_combinations"
      - "test_grid_output_format"

  phase_4:
    name: "Analysis and Documentation"
    status: "PLANNED"
    deliverables:
      - "Run comprehensive sweeps"
      - "Document findings in balance-tuning.yaml"
      - "Identify parameter interactions"
      - "Validate theoretical predictions"

# =============================================================================
# MISE TASKS (to be added)
# =============================================================================

mise_tasks:
  - name: "analyze-trace"
    command: "poetry run python tools/parameter_analysis.py trace"
    description: "Run single simulation with full time-series output"

  - name: "analyze-sweep"
    command: "poetry run python tools/parameter_analysis.py sweep"
    description: "Run parameter sweep with rich metrics"

  - name: "analyze-grid"
    command: "poetry run python tools/parameter_analysis.py grid"
    description: "Run 2D parameter grid search"
